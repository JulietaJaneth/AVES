{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a317f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3cd1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Io:\n",
    "    \n",
    "        def __init__(self):\n",
    "            pass\n",
    "       \n",
    "        \n",
    "        def spectrogram(self,audio_path = None):\n",
    "            waveform, sample_rate = torchaudio.load(audio_path)\n",
    "            print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "            print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "            # Plot de waveforms\n",
    "\n",
    "            # plt.figure()\n",
    "            # plt.plot(waveform.t().numpy())\n",
    "\n",
    "            tensor = torchaudio.transforms.Spectrogram()(waveform) #many arguments to modificate the spectrogram \n",
    "\n",
    "            print(\"Shape of spectrogram: {}\".format(tensor.size()))\n",
    "\n",
    "            plt.figure()\n",
    "            pylab.matshow(tensor.log2()[0,:,:].numpy(), cmap=pylab.get_cmap('plasma'))\n",
    "\n",
    "            self.tensor = tensor\n",
    "\n",
    "\n",
    "        def mel(self, audio_path = None, n_mels = 128,f_min = 0.0, f_max = None, n_stft = None, norm = None):\n",
    "            \"\"\"Implementation of torchaudio.transforms.MelScale. \n",
    "                Turn a normal STFT into a mel frequency STFT, using a conversion matrix. \n",
    "                This uses triangular filter banks.\n",
    "                \n",
    "                Inputs\n",
    "                ------\n",
    "                    audio_path: str\n",
    "                        Path to the file that contains the audio.\n",
    "                    n_mels: int, default 128\n",
    "                        Number of mel filterbanks.\n",
    "                    sample_rate: int, default 1600\n",
    "\n",
    "                    f_min: float, default 0\n",
    "                        Minimum frequency. \n",
    "                    f_max: float, default sample_rate // 2 (sample_rate obtained by torchaudio.load)\n",
    "                        Maximum frequency.\n",
    "                    n_stft: int, default None\n",
    "                        Number of bins in STFT. Calculated from first input if None is given.\n",
    "                    norm: str, default None\n",
    "\n",
    "                Forward\n",
    "                -------\n",
    "                    Parameters:\n",
    "                    \n",
    "                        specgram: Tensor\n",
    "                            A spectrogram STFT of dimension (…, freq, time).\n",
    "\n",
    "                    Return: Tensor\n",
    "                            Mel frequency spectrogram of size (…, n_mels, time).\"\"\"\n",
    "            waveform, sr = torchaudio.load(audio_path)\n",
    "            melScale = torchaudio.transforms.MelScale(n_mels = n_mels, sample_rate = sr, f_min = f_min, f_max = f_max, n_stft = n_stft, norm = norm)(waveform)\n",
    "            self.melScale = melScale\n",
    "            return melScale\n",
    "\n",
    "        def mfcc(self):\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fdd953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
